### 1. **K-Nearest Neighbors (KNN)**
   - `n_neighbors` (required): Number of neighbors to consider for classification or regression.
   - `weights`: Weighting function (`uniform`, `distance`, or custom function).
   - `algorithm`: Algorithm used to compute nearest neighbors (`auto`, `ball_tree`, `kd_tree`, `brute`).
   - `leaf_size`: Size of leaf nodes in `ball_tree` or `kd_tree` (affects speed).
   - `p`: Power parameter for the Minkowski metric (1 = Manhattan, 2 = Euclidean).
   - `metric`: Distance metric (default is Minkowski).

### 2. **Decision Tree (Classification)**
   - `criterion`: Function to measure split quality (`gini` or `entropy`).
   - `splitter`: Strategy for splitting at each node (`best` or `random`).
   - `max_depth`: Maximum tree depth (limits overfitting).
   - `min_samples_split`: Minimum samples required to split an internal node.
   - `min_samples_leaf`: Minimum samples required to be a leaf node.
   - `max_features`: Number of features to consider when looking for the best split.
   - `max_leaf_nodes`: Maximum number of leaf nodes in the tree.
   - `min_impurity_decrease`: Minimum impurity decrease for a node split.
   - `class_weight`: Weights associated with classes (useful for imbalanced datasets).

### 3. **Random Forest (Classification)**
   - `n_estimators` (required): Number of trees in the forest.
   - `criterion`: Function to measure split quality (`gini` or `entropy`).
   - `max_depth`: Maximum depth of each tree.
   - `min_samples_split`: Minimum samples required to split an internal node.
   - `min_samples_leaf`: Minimum samples required to be a leaf node.
   - `max_features`: Number of features to consider at each split.
   - `bootstrap`: Whether to use bootstrap samples for building trees.
   - `oob_score`: Whether to use out-of-bag samples to estimate accuracy.
   - `n_jobs`: Number of jobs for parallel execution (use -1 for all processors).
   - `random_state`: Seed for random number generation.
   - `class_weight`: Weights associated with classes.

### 4. **Logistic Regression**
   - `penalty`: Regularization term (`l1`, `l2`, `elasticnet`, `none`).
   - `C`: Inverse of regularization strength (smaller values mean stronger regularization).
   - `solver`: Optimization algorithm (`liblinear`, `saga`, `newton-cg`, etc.).
   - `max_iter`: Maximum number of iterations.
   - `multi_class`: `ovr` for one-vs-rest or `multinomial` for multiclass settings.
   - `class_weight`: Weights associated with classes.
   - `l1_ratio`: Used only for `elasticnet` penalty, mix of L1 and L2 regularization.

### 5. **Support Vector Machine (SVM)**
   - `C`: Regularization parameter.
   - `kernel`: Kernel type (`linear`, `poly`, `rbf`, `sigmoid`, `precomputed`).
   - `degree`: Degree for `poly` kernel.
   - `gamma`: Kernel coefficient for `rbf`, `poly`, and `sigmoid` kernels.
   - `coef0`: Independent term in kernel function (`poly` and `sigmoid`).
   - `class_weight`: Weights associated with classes.
   - `probability`: Whether to enable probability estimates.

### 6. **Naive Bayes**
   - **Gaussian Naive Bayes**:
     - `var_smoothing`: Portion of the largest variance added to variances for stability.
   - **Multinomial Naive Bayes**:
     - `alpha`: Additive (Laplace/Lidstone) smoothing parameter.
   - **Complement Naive Bayes**:
     - `alpha`: Smoothing parameter.
   - **Bernoulli Naive Bayes**:
     - `alpha`: Smoothing parameter.
     - `binarize`: Threshold for binarizing data (if applicable).

### 7. **Linear Regression**
   - `fit_intercept`: Whether to calculate the intercept.
   - `normalize`: If True, normalizes data (deprecated in newer versions of scikit-learn).
   - `n_jobs`: Number of jobs for parallel computation.
   - `positive`: If True, restricts coefficients to be positive.

### 8. **Lasso Regression**
   - `alpha`: Regularization strength (higher values mean more regularization).
   - `fit_intercept`: Whether to calculate the intercept.
   - `max_iter`: Maximum number of iterations.
   - `tol`: Tolerance for optimization.
   - `selection`: Method for coordinate descent (`cyclic` or `random`).

### 9. **Ridge Regression**
   - `alpha`: Regularization strength (higher values mean more regularization).
   - `fit_intercept`: Whether to calculate the intercept.
   - `normalize`: If True, normalizes data (deprecated in newer versions of scikit-learn).
   - `solver`: Solver to use for optimization (`auto`, `svd`, `cholesky`, etc.).
   - `tol`: Tolerance for optimization.

### 10. **Decision Tree Regression**
   - `criterion`: Function to measure split quality (`mse`, `friedman_mse`, or `mae`).
   - `splitter`: Strategy for splitting (`best` or `random`).
   - `max_depth`: Maximum depth of the tree.
   - `min_samples_split`: Minimum samples required to split a node.
   - `min_samples_leaf`: Minimum samples required to be a leaf node.
   - `max_features`: Number of features to consider for the best split.
   - `max_leaf_nodes`: Maximum number of leaf nodes.
   - `min_impurity_decrease`: Minimum impurity decrease for split.

### 11. **Random Forest Regression**
   - `n_estimators`: Number of trees in the forest.
   - `criterion`: Function to measure split quality (`mse`, `mae`).
   - `max_depth`: Maximum depth of each tree.
   - `min_samples_split`: Minimum samples required to split a node.
   - `min_samples_leaf`: Minimum samples required to be a leaf node.
   - `max_features`: Number of features to consider for the best split.
   - `bootstrap`: Whether to use bootstrap samples.
   - `oob_score`: Whether to use out-of-bag samples for estimation.
   - `n_jobs`: Number of jobs for parallel processing.
   - `random_state`: Seed for random number generation.

### 12. **K-Means Clustering**
   - `n_clusters`: Number of clusters.
   - `init`: Method for initialization (`k-means++`, `random`).
   - `n_init`: Number of times algorithm will run with different initializations.
   - `max_iter`: Maximum number of iterations.
   - `tol`: Tolerance to declare convergence.
   - `algorithm`: Algorithm to use for computing clusters (`auto`, `full`, `elkan`).

### 13. **Hierarchical Clustering**
   - `n_clusters`: Number of clusters.
   - `affinity`: Metric used to compute linkage (`euclidean`, `l1`, `l2`, `manhattan`, etc.).
   - `memory`: Used to cache results (usually `None`).
   - `connectivity`: Connectivity matrix for spatially constrained clustering.
   - `linkage`: Linkage criterion (`ward`, `complete`, `average`, `single`).
   - `distance_threshold`: Clustering distance threshold (useful when `n_clusters` is not specified).
